{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "016ca6aa",
   "metadata": {},
   "source": [
    "# Acoustic Shield - Training Data Pipeline\n",
    "\n",
    "This notebook orchestrates the complete data pipeline:\n",
    "1. Extract crash hotspots from GeoJSON\n",
    "2. Enrich with weather data (Open-Meteo API)\n",
    "3. Synthesize risk events\n",
    "4. Build audio generation recipes\n",
    "5. Run SageMaker Processing job to generate WAV files\n",
    "6. Validate outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1867be2",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d0689b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:27:12.601610Z",
     "iopub.status.busy": "2025-10-26T02:27:12.601478Z",
     "iopub.status.idle": "2025-10-26T02:27:14.046470Z",
     "shell.execute_reply": "2025-10-26T02:27:14.045931Z",
     "shell.execute_reply.started": "2025-10-26T02:27:12.601595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "‚úì Imports complete\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "import boto3\n",
    "from sagemaker import Session\n",
    "from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "\n",
    "from data_pipeline import (\n",
    "    S3Client,\n",
    "    HotspotExtractor,\n",
    "    WeatherEnricher,\n",
    "    RiskEventSynthesizer,\n",
    "    RecipeBuilder\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úì Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b451c409",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:27:14.047076Z",
     "iopub.status.busy": "2025-10-26T02:27:14.046926Z",
     "iopub.status.idle": "2025-10-26T02:27:14.354941Z",
     "shell.execute_reply": "2025-10-26T02:27:14.354414Z",
     "shell.execute_reply.started": "2025-10-26T02:27:14.047061Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:\n",
      "  Raw bucket: acousticshield-raw\n",
      "  ML bucket: acousticshield-ml\n",
      "  Region: us-east-1\n",
      "  SageMaker role: arn:aws:iam::764040442724:role/role-sagemaker-processing\n",
      "  Crash file: s3://acousticshield-raw/crash_hotspots/sanjose_crashes.geojson\n",
      "  Top hotspots: 100000\n",
      "  Events per hotspot: 4\n"
     ]
    }
   ],
   "source": [
    "# Configuration - No hard-coded regions!\n",
    "RAW_BUCKET = 'acousticshield-raw'\n",
    "ML_BUCKET = 'acousticshield-ml'\n",
    "CRASH_FILE_KEY = 'crash_hotspots/sanjose_crashes.geojson'\n",
    "SAGEMAKER_ROLE = 'role-sagemaker-processing'\n",
    "\n",
    "# Processing parameters\n",
    "TOP_N_HOTSPOTS = 100000\n",
    "EVENTS_PER_HOTSPOT = 4\n",
    "\n",
    "# Get region from bucket\n",
    "s3_client = S3Client()\n",
    "REGION = s3_client.get_bucket_region(RAW_BUCKET)\n",
    "\n",
    "# Initialize SageMaker session and get role ARN\n",
    "sagemaker_session = Session(boto_session=boto3.Session(region_name=REGION))\n",
    "try:\n",
    "    # Try to get role ARN from SageMaker\n",
    "    role = sagemaker_session.get_execution_role()\n",
    "except:\n",
    "    # If not in SageMaker environment, construct role ARN\n",
    "    account_id = boto3.client('sts', region_name=REGION).get_caller_identity()['Account']\n",
    "    role = f'arn:aws:iam::{account_id}:role/{SAGEMAKER_ROLE}'\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Raw bucket: {RAW_BUCKET}\")\n",
    "print(f\"  ML bucket: {ML_BUCKET}\")\n",
    "print(f\"  Region: {REGION}\")\n",
    "print(f\"  SageMaker role: {role}\")\n",
    "print(f\"  Crash file: s3://{RAW_BUCKET}/{CRASH_FILE_KEY}\")\n",
    "print(f\"  Top hotspots: {TOP_N_HOTSPOTS}\")\n",
    "print(f\"  Events per hotspot: {EVENTS_PER_HOTSPOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdde042",
   "metadata": {},
   "source": [
    "## Step 1: Extract Crash Hotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09107bc-fba6-40a6-b546-37286acf777b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:27:14.357137Z",
     "iopub.status.busy": "2025-10-26T02:27:14.356969Z",
     "iopub.status.idle": "2025-10-26T02:27:42.485652Z",
     "shell.execute_reply": "2025-10-26T02:27:42.485082Z",
     "shell.execute_reply.started": "2025-10-26T02:27:14.357120Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 02:27:14,357 - __main__ - INFO - Loading crash data from s3://acousticshield-raw/crash_hotspots/sanjose_crashes.geojson\n"
     ]
    }
   ],
   "source": [
    "# Load crash data from S3\n",
    "logger.info(f\"Loading crash data from s3://{RAW_BUCKET}/{CRASH_FILE_KEY}\")\n",
    "crash_data = s3_client.read_json(RAW_BUCKET, CRASH_FILE_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43c2d83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:27:42.486392Z",
     "iopub.status.busy": "2025-10-26T02:27:42.486234Z",
     "iopub.status.idle": "2025-10-26T02:27:51.171192Z",
     "shell.execute_reply": "2025-10-26T02:27:51.170657Z",
     "shell.execute_reply.started": "2025-10-26T02:27:42.486377Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 02:27:48,841 - data_pipeline.hotspot_extractor - INFO - Loaded 601960 crash records\n",
      "2025-10-26 02:27:50,756 - data_pipeline.hotspot_extractor - INFO - Extracted 11855 hotspots with enhanced metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Crash Data Summary:\n",
      "  Total crashes: 601960\n",
      "  Total injuries: 243924\n",
      "  Total fatalities: 2342\n",
      "  Speeding involved: 3.9%\n",
      "\n",
      "üéØ Top 5 Hotspots:\n",
      "  1. KING RD & STORY RD: 2861 crashes\n",
      "  2. CAPITOL EX & SENTER RD: 2807 crashes\n",
      "  3. CAPITOL EX & STORY RD: 2781 crashes\n",
      "  4. CAPITOL AV & MCKEE RD: 2493 crashes\n",
      "  5. BLOSSOM HILL RD & SNELL AV: 2410 crashes\n",
      "11855\n"
     ]
    }
   ],
   "source": [
    "# Extract hotspots\n",
    "extractor = HotspotExtractor(crash_data)\n",
    "hotspots = extractor.extract_top_hotspots(top_n=TOP_N_HOTSPOTS)\n",
    "\n",
    "# Get summary stats\n",
    "stats = extractor.get_summary_stats()\n",
    "print(f\"\\nüìä Crash Data Summary:\")\n",
    "print(f\"  Total crashes: {stats['total_crashes']}\")\n",
    "print(f\"  Total injuries: {stats['total_injuries']}\")\n",
    "print(f\"  Total fatalities: {stats['total_fatalities']}\")\n",
    "print(f\"  Speeding involved: {stats['speeding_involved_pct']:.1f}%\")\n",
    "\n",
    "print(f\"\\nüéØ Top 5 Hotspots:\")\n",
    "for hotspot in hotspots[:5]:\n",
    "    print(f\"  {hotspot['rank']}. {hotspot['location_name']}: {hotspot['crash_count']} crashes\")\n",
    "print(len(hotspots))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855c995",
   "metadata": {},
   "source": [
    "## Step 2: Enrich with Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de0519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T02:27:51.174358Z",
     "iopub.status.busy": "2025-10-26T02:27:51.174208Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 02:27:51,175 - __main__ - INFO - Fetching weather data for hotspots...\n",
      "2025-10-26 02:27:51,190 - data_pipeline.weather_enricher - INFO - Fetching weather for 10162 unique coordinates (from 11855 hotspots) with 16 workers...\n"
     ]
    }
   ],
   "source": [
    "# Enrich hotspots with weather data from Open-Meteo API\n",
    "logger.info(\"Fetching weather data for hotspots...\")\n",
    "enricher = WeatherEnricher()\n",
    "enriched_hotspots = enricher.enrich_hotspots(hotspots, rate_limit_delay=0.5)\n",
    "\n",
    "# Show sample enriched data\n",
    "print(f\"\\nüå§Ô∏è  Sample Enriched Hotspot:\")\n",
    "sample = enriched_hotspots[0]\n",
    "print(f\"  Location: {sample['location_name']}\")\n",
    "print(f\"  Crashes: {sample['crash_count']}\")\n",
    "print(f\"  Weather:\")\n",
    "weather = sample['weather']\n",
    "print(f\"    Temperature: {weather['temperature_c']:.1f}¬∞C\")\n",
    "print(f\"    Rain: {weather['rain_mm']:.1f}mm\")\n",
    "print(f\"    Wind: {weather['wind_speed_kmh']:.1f} km/h\")\n",
    "print(f\"    Risk: {enricher.categorize_weather_risk(weather)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d68f76",
   "metadata": {},
   "source": [
    "## Step 3: Synthesize Risk Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4097ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic risk events\n",
    "logger.info(\"Synthesizing risk events...\")\n",
    "synthesizer = RiskEventSynthesizer(seed=42)\n",
    "risk_events = synthesizer.synthesize_events(enriched_hotspots, events_per_hotspot=EVENTS_PER_HOTSPOT)\n",
    "\n",
    "# Get distribution\n",
    "distribution = synthesizer.get_event_distribution(risk_events)\n",
    "print(f\"\\n‚ö†Ô∏è  Risk Event Distribution:\")\n",
    "print(f\"  Total events: {distribution['total_events']}\")\n",
    "print(f\"  By risk type:\")\n",
    "for risk_type, count in distribution['risk_type_distribution'].items():\n",
    "    print(f\"    {risk_type}: {count}\")\n",
    "print(f\"  By weather risk:\")\n",
    "for weather_risk, count in distribution['weather_risk_distribution'].items():\n",
    "    print(f\"    {weather_risk}: {count}\")\n",
    "\n",
    "# Show sample event\n",
    "print(f\"\\nüìã Sample Risk Event:\")\n",
    "sample_event = risk_events[0]\n",
    "print(json.dumps(sample_event, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63018e86",
   "metadata": {},
   "source": [
    "## Step 4: Build Audio Recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d423e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build audio generation recipes\n",
    "logger.info(\"Building audio recipes...\")\n",
    "builder = RecipeBuilder()\n",
    "recipes = builder.build_recipes(risk_events)\n",
    "\n",
    "# Get summary\n",
    "summary = builder.get_recipe_summary(recipes)\n",
    "print(f\"\\nüéµ Audio Recipe Summary:\")\n",
    "print(f\"  Total recipes: {summary['total_recipes']}\")\n",
    "print(f\"  Total audio duration: {summary['total_audio_duration_minutes']:.2f} minutes\")\n",
    "print(f\"  By risk type:\")\n",
    "for risk_type, count in summary['risk_type_distribution'].items():\n",
    "    print(f\"    {risk_type}: {count} recipes\")\n",
    "\n",
    "# Show sample recipe\n",
    "print(f\"\\nüéº Sample Recipe:\")\n",
    "sample_recipe = recipes[0]\n",
    "print(json.dumps(sample_recipe, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ab018",
   "metadata": {},
   "source": [
    "## Step 5: Save Intermediate Data to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52765b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save risk events to S3\n",
    "logger.info(\"Saving risk events to S3...\")\n",
    "risk_events_key = 'risk_events/risk_events.json'\n",
    "s3_path = s3_client.write_json(risk_events, RAW_BUCKET, risk_events_key)\n",
    "print(f\"‚úì Risk events saved to: {s3_path}\")\n",
    "\n",
    "# Save individual recipe files to S3 (required for processing job)\n",
    "logger.info(\"Saving individual recipe files to S3...\")\n",
    "s3 = boto3.client('s3', region_name=REGION)\n",
    "recipe_count = 0\n",
    "for recipe in recipes:\n",
    "    recipe_id = recipe.get('recipe_id', f'recipe_{recipe_count:05d}')\n",
    "    recipe_key = f'recipes/train/{recipe_id}.json'\n",
    "    s3.put_object(\n",
    "        Bucket=ML_BUCKET,\n",
    "        Key=recipe_key,\n",
    "        Body=json.dumps(recipe, indent=2),\n",
    "        ContentType='application/json'\n",
    "    )\n",
    "    recipe_count += 1\n",
    "\n",
    "print(f\"‚úì {recipe_count} recipe files saved to: s3://{ML_BUCKET}/recipes/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a681ea6",
   "metadata": {},
   "source": [
    "## Step 6: Generate AI-Enhanced Audio WAV Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08fb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate AI-Enhanced Audio WAV Files\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéµ STEP 6: GENERATE AI-ENHANCED AUDIO WAV FILES\")\n",
    "print(\"=\"*70)\n",
    "print(\"Using Bedrock AI to optimize audio parameters for realistic sound\")\n",
    "\n",
    "try:\n",
    "    from sagemaker.processing import ScriptProcessor, ProcessingInput, ProcessingOutput\n",
    "    \n",
    "    # Create processor\n",
    "    processor = ScriptProcessor(\n",
    "        role=role,\n",
    "        image_uri=f'764040442724.dkr.ecr.us-east-1.amazonaws.com/cpu-pytorch-boto-update:custom-reqs-20251026-0044',\n",
    "        command=['python3'],\n",
    "        instance_count=25,\n",
    "        instance_type=\"ml.c5.2xlarge\",\n",
    "        volume_size_in_gb=200,\n",
    "        max_runtime_in_seconds=36000\n",
    "        base_job_name='acousticshield-audio-gen',\n",
    "        sagemaker_session=sagemaker_session\n",
    "    )\n",
    "    \n",
    "    # Run processing job\n",
    "    processor.run(\n",
    "        inputs=[\n",
    "            ProcessingInput(\n",
    "                source=f's3://{ML_BUCKET}/recipes/train/',\n",
    "                destination='/opt/ml/processing/input'\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            ProcessingOutput(\n",
    "                output_name='audio_wav',\n",
    "                source='/opt/ml/processing/output',\n",
    "                destination=f's3://{ML_BUCKET}/train/'\n",
    "            )\n",
    "        ],\n",
    "        code='../processing/bedrock_audio_generator.py',\n",
    "        arguments=['--region', REGION],  # AI enabled by default\n",
    "        wait=True,\n",
    "        logs=True\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ AI-enhanced WAV file generation complete!\")\n",
    "    print(\"üí° Audio parameters optimized by Bedrock Claude AI\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d1de0b",
   "metadata": {},
   "source": [
    "## Step 7: Validate Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c64575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List generated WAV files\n",
    "s3 = boto3.client('s3', region_name=REGION)\n",
    "wav_files = []\n",
    "\n",
    "response = s3.list_objects_v2(Bucket=ML_BUCKET, Prefix='train/')\n",
    "if 'Contents' in response:\n",
    "    wav_files = [obj['Key'] for obj in response['Contents'] if obj['Key'].endswith('.wav')]\n",
    "\n",
    "print(f\"\\nüéµ Generated WAV Files: {len(wav_files)}\")\n",
    "if wav_files:\n",
    "    print(f\"First 10 files:\")\n",
    "    for f in wav_files[:10]:\n",
    "        print(f\"  {f}\")\n",
    "\n",
    "if len(wav_files) > 10:\n",
    "    print(f\"    ... and {len(wav_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d50d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count WAV files by risk type\n",
    "risk_type_counts = {'normal': 0, 'tireskid': 0, 'emergencybraking': 0, 'collisionimminent': 0}\n",
    "\n",
    "for wav_file in wav_files:\n",
    "    filename = wav_file.lower()\n",
    "    for risk_type in risk_type_counts.keys():\n",
    "        if risk_type in filename:\n",
    "            risk_type_counts[risk_type] += 1\n",
    "            break\n",
    "\n",
    "print(f\"\\nüìä WAV Files by Risk Type:\")\n",
    "for risk_type, count in risk_type_counts.items():\n",
    "    print(f\"  {risk_type.title()}: {count} files\")\n",
    "\n",
    "# Show sample file info\n",
    "if wav_files:\n",
    "    print(f\"\\nüìã Sample WAV File:\")\n",
    "    sample_key = wav_files[0]\n",
    "    obj = s3.head_object(Bucket=ML_BUCKET, Key=sample_key)\n",
    "    print(f\"  File: {sample_key}\")\n",
    "    print(f\"  Size: {obj['ContentLength']:,} bytes\")\n",
    "    print(f\"  Duration: ~5 seconds @ 22.05kHz\")\n",
    "    print(f\"  Format: 16-bit PCM WAV\")\n",
    "    print(f\"\\n‚úÖ Files are ready for ML training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9759dd9",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311c4442",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ ACOUSTIC SHIELD DATA PIPELINE COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nüìç Crash Hotspots Analyzed: {len(hotspots)}\")\n",
    "print(f\"‚ö†Ô∏è  Risk Events Generated: {len(risk_events)}\")\n",
    "print(f\"üéµ Audio Recipes Created: {len(recipes)}\")\n",
    "print(f\"ü§ñ AI-Enhanced WAV Files: {len(wav_files)}\")\n",
    "print(f\"\\nüíæ Data Locations:\")\n",
    "print(f\"  Risk Events: s3://{RAW_BUCKET}/{risk_events_key}\")\n",
    "# print(f\"  Recipes: s3://{RAW_BUCKET}/{recipes_key}\")\n",
    "print(f\"  Audio Files: s3://{ML_BUCKET}/train/\")\n",
    "print(f\"\\n‚úÖ Ready for ML model training!\")\n",
    "print(f\"üß† All audio parameters optimized by Bedrock AI\")\n",
    "print(f\"üéØ Each risk type has distinct audio characteristics\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a2862-f797-45bb-9298-cd9157fb8f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
